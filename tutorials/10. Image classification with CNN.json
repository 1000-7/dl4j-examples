{"paragraphs":[{"text":"%md\n### Note\n\nPlease view the [README](https://github.com/deeplearning4j/deeplearning4j/tree/master/dl4j-examples/tutorials/README.md) to learn about installing, setting up dependencies, and importing notebooks in Zeppelin","user":"anonymous","dateUpdated":"2017-11-20T15:07:08+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Note</h3>\n<p>Please view the <a href=\"https://github.com/deeplearning4j/deeplearning4j/tree/master/dl4j-examples/tutorials/README.md\">README</a> to learn about installing, setting up dependencies, and importing notebooks in Zeppelin</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1511006694416_-1542005133","id":"20171020-070156_1850232313","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:08+0000","dateFinished":"2017-11-20T15:07:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9190"},{"text":"%md\n\n### Background\n\n#### Convolutional Neural Networks (CNN)\nThe main task we want neural networks to perform is to extract features from the data that it is being fed with. We have previously dealt with feedforward fully-connected neural networks which just multiply our inputs with the weights and adds the biases and learns and adjust them iteratively. As a result, the network surely learns about the features in the form of weights and biases but it doesn't concerns itself with the surrounding input values. For us this is important because sometimes the input values only makes sense in the form of a group. \n\nTo learn such type of features we need to use a set of weights, in the form of a matrix, as a feature. Such a set of weights is called a kernel (also known as filters in 2D convolutions). These kernels are best suited for training with images. They slide over the input images and gives responses as another matrix. \n\nAt the last few layers of a CNN we have some fully-connected layers which then transforms our learned features into a set of predictions on which we can analyse our network's performance.\n\n--- \n\n#### Goals\n- Learn about how CNN works\n- Working with CNN in DL4J","user":"anonymous","dateUpdated":"2017-11-20T15:07:08+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Background</h3>\n<h4>Convolutional Neural Networks (CNN)</h4>\n<p>The main task we want neural networks to perform is to extract features from the data that it is being fed with. We have previously dealt with feedforward fully-connected neural networks which just multiply our inputs with the weights and adds the biases and learns and adjust them iteratively. As a result, the network surely learns about the features in the form of weights and biases but it doesn&rsquo;t concerns itself with the surrounding input values. For us this is important because sometimes the input values only makes sense in the form of a group. </p>\n<p>To learn such type of features we need to use a set of weights, in the form of a matrix, as a feature. Such a set of weights is called a kernel (also known as filters in 2D convolutions). These kernels are best suited for training with images. They slide over the input images and gives responses as another matrix. </p>\n<p>At the last few layers of a CNN we have some fully-connected layers which then transforms our learned features into a set of predictions on which we can analyse our network&rsquo;s performance.</p>\n<hr/>\n<h4>Goals</h4>\n<ul>\n  <li>Learn about how CNN works</li>\n  <li>Working with CNN in DL4J</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1511006694423_-598692174","id":"20171020-070208_2069142559","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:09+0000","dateFinished":"2017-11-20T15:07:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9191"},{"text":"%md\n\n## 1. How CNN works\n\n### Basic concept\n\nAt each convolutional layer, the network learns about different features from the data. As the features goes deeper into the inner CNN layers, the features get more and more general. For example, at the first CNN layer the kernels might be learning about the edges present in the images. In the later layers, the network might be learning about corners or different shapes (which might be a combination of edges). The following image shows the features learned by the network for face detection:\n\n|---|---|---|---|\n|Features learned by the network|![Features learned by the network](http://parse.ele.tue.nl/cluster/0/fig1.png)|[Source](http://parse.ele.tue.nl/cluster/0/fig1.png)|[Site](http://derekjanni.github.io/Easy-Neural-Nets/)|\n\n___Figure 1:___ The above network shows how more generalized features are learned at each layer of the network.\n\n|---|---|---|---|\n|Basic convolution operation|![Basic convolution operation](http://www.songho.ca/dsp/convolution/files/conv2d_matrix.jpg)|[Source](http://www.songho.ca/dsp/convolution/files/conv2d_matrix.jpg)|[Site](http://www.songho.ca/dsp/convolution/convolution.html)|\n\n___Figure 2:___ The above figure shows how a basic convolution operation is calculated. It's just a weighted sum of the corresponding matrix values (input and kernel)\n\n### CNN related terms\n\n- Strides\n    _It tells the convolutional layer how many columns or rows (or both) it should skip while sliding the kernel over the inputs. This results in decreasing the output volume. Thus having less number of network parameters._\n\n- Padding\n    _It tells us how many zeros to append at every end of the matrix. This can help us in controlling the output volume._\n\n- Pooling\n    _Pooling layer (also subsampling layer) helps us in reducing the network parameters by appling different types of filtering or other mathematical operations to the output convolutional responses. Pooling has different types - such as, Max pooling, average pooling, L2-norm. Max pooling is the most commonly used pooling type, as it gets the maximum of all the values covered by the kernel specified._","user":"anonymous","dateUpdated":"2017-11-20T15:07:08+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1. How CNN works</h2>\n<h3>Basic concept</h3>\n<p>At each convolutional layer, the network learns about different features from the data. As the features goes deeper into the inner CNN layers, the features get more and more general. For example, at the first CNN layer the kernels might be learning about the edges present in the images. In the later layers, the network might be learning about corners or different shapes (which might be a combination of edges). The following image shows the features learned by the network for face detection:</p>\n<table>\n  <tbody>\n    <tr>\n      <td>Features learned by the network</td>\n      <td><img src=\"http://parse.ele.tue.nl/cluster/0/fig1.png\" alt=\"Features learned by the network\" /></td>\n      <td><a href=\"http://parse.ele.tue.nl/cluster/0/fig1.png\">Source</a></td>\n      <td><a href=\"http://derekjanni.github.io/Easy-Neural-Nets/\">Site</a></td>\n    </tr>\n  </tbody>\n</table>\n<p><strong><em>Figure 1:</em></strong> The above network shows how more generalized features are learned at each layer of the network.</p>\n<table>\n  <tbody>\n    <tr>\n      <td>Basic convolution operation</td>\n      <td><img src=\"http://www.songho.ca/dsp/convolution/files/conv2d_matrix.jpg\" alt=\"Basic convolution operation\" /></td>\n      <td><a href=\"http://www.songho.ca/dsp/convolution/files/conv2d_matrix.jpg\">Source</a></td>\n      <td><a href=\"http://www.songho.ca/dsp/convolution/convolution.html\">Site</a></td>\n    </tr>\n  </tbody>\n</table>\n<p><strong><em>Figure 2:</em></strong> The above figure shows how a basic convolution operation is calculated. It&rsquo;s just a weighted sum of the corresponding matrix values (input and kernel)</p>\n<h3>CNN related terms</h3>\n<ul>\n  <li>\n  <p>Strides<br/><em>It tells the convolutional layer how many columns or rows (or both) it should skip while sliding the kernel over the inputs. This results in decreasing the output volume. Thus having less number of network parameters.</em></p></li>\n  <li>\n  <p>Padding<br/><em>It tells us how many zeros to append at every end of the matrix. This can help us in controlling the output volume.</em></p></li>\n  <li>\n  <p>Pooling<br/><em>Pooling layer (also subsampling layer) helps us in reducing the network parameters by appling different types of filtering or other mathematical operations to the output convolutional responses. Pooling has different types - such as, Max pooling, average pooling, L2-norm. Max pooling is the most commonly used pooling type, as it gets the maximum of all the values covered by the kernel specified.</em></p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1511006694424_53043252","id":"20171116-134509_791025875","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:09+0000","dateFinished":"2017-11-20T15:07:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9192"},{"text":"%md\n## 2. CNN in DL4J\nLet's see how all of this works in DL4J\n\nYou can build a convolutional layer in DL4J as:\n```\nval convLayer = new ConvolutionLayer.Builder(Array[Int](5, 5), Array[Int](1, 1), Array[Int](0, 0))\n        .name(\"cnn\").nOut(50).biasInit(0).build\n```\nHere the convolutional layer is being applied with a kernel size of _5x5_ and stride of _1x1_ and a padding of _0x0_ with _50_ kernels and all biases initialized to _0_\n\nThe output is of the shape (WoxHoxDo) for a convolutional layer:\nWo=(W−Fw+2Ph)/Sh+1 -> W is the input width, Fw is the kernel width, Ph is the horizontal padding, Sh is the horizontal stride\nHo=(H−Fh+2Pv)/Sv+1 -> H is the input height, Fh is the kernel height, Pv is the vertical padding, Sv is the vertical stride\nDo=K -> K is the number of kernels applied\n\nFor a pooling layer we can do something like this:\n```\nval poolLayer = new SubsamplingLayer.Builder(Array[Int](2, 2), Array[Int](2, 2)).name(\"maxpool\").build\n```\nThe default type of pooling is max pooling. Here we're building a pooling layer with a kernel size of _2x2_ and a stride of _2x2_\n\nThe output is of the shape (WoxHoxDo) for a pooling layer: \nWo = (W−Fw)/Sh+1 -> W is the input width, Fw is the kernel width, Sh is the horizontal stride\nHo = (H−Fh)/Sv+1 -> H is the input height, Fh is the kernel height, Sv is the vertical stride\nDo = Di -> Di is the input depth\n\nAlso we have to tell our network configuration how we are passing the inputs to it. If it's already an image then we can do:\n```\nval conf = new NeuralNetConfiguration.Builder()\n// Hyperparameters code here\n.list\n// Layers code here\n.setInputType(InputType.convolutional(32, 32, 3)) // Setting our input type here (32x32x3 image)\n.build\n```\n\nOtherwise, if it's a linear array of inputs, we can do something like this:\n```\nval conf = new NeuralNetConfiguration.Builder()\n// Hyperparameters code here\n.list\n// Layers code here\n.setInputType(InputType.convolutionalFlat(28, 28, 1)) // Setting our input type here (784 linear array input converted to 28x28x1 input)\n.build\n```","user":"anonymous","dateUpdated":"2017-11-20T15:07:09+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{"0":{"graph":{"mode":"table","height":386.188,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2. CNN in DL4J</h2>\n<p>Let&rsquo;s see how all of this works in DL4J</p>\n<p>You can build a convolutional layer in DL4J as:</p>\n<pre><code>val convLayer = new ConvolutionLayer.Builder(Array[Int](5, 5), Array[Int](1, 1), Array[Int](0, 0))\n        .name(&quot;cnn&quot;).nOut(50).biasInit(0).build\n</code></pre>\n<p>Here the convolutional layer is being applied with a kernel size of <em>5x5</em> and stride of <em>1x1</em> and a padding of <em>0x0</em> with <em>50</em> kernels and all biases initialized to <em>0</em></p>\n<p>The output is of the shape (WoxHoxDo) for a convolutional layer:<br/>Wo=(W−Fw+2Ph)/Sh+1 -&gt; W is the input width, Fw is the kernel width, Ph is the horizontal padding, Sh is the horizontal stride<br/>Ho=(H−Fh+2Pv)/Sv+1 -&gt; H is the input height, Fh is the kernel height, Pv is the vertical padding, Sv is the vertical stride<br/>Do=K -&gt; K is the number of kernels applied</p>\n<p>For a pooling layer we can do something like this:</p>\n<pre><code>val poolLayer = new SubsamplingLayer.Builder(Array[Int](2, 2), Array[Int](2, 2)).name(&quot;maxpool&quot;).build\n</code></pre>\n<p>The default type of pooling is max pooling. Here we&rsquo;re building a pooling layer with a kernel size of <em>2x2</em> and a stride of <em>2x2</em></p>\n<p>The output is of the shape (WoxHoxDo) for a pooling layer:<br/>Wo = (W−Fw)/Sh+1 -&gt; W is the input width, Fw is the kernel width, Sh is the horizontal stride<br/>Ho = (H−Fh)/Sv+1 -&gt; H is the input height, Fh is the kernel height, Sv is the vertical stride<br/>Do = Di -&gt; Di is the input depth</p>\n<p>Also we have to tell our network configuration how we are passing the inputs to it. If it&rsquo;s already an image then we can do:</p>\n<pre><code>val conf = new NeuralNetConfiguration.Builder()\n// Hyperparameters code here\n.list\n// Layers code here\n.setInputType(InputType.convolutional(32, 32, 3)) // Setting our input type here (32x32x3 image)\n.build\n</code></pre>\n<p>Otherwise, if it&rsquo;s a linear array of inputs, we can do something like this:</p>\n<pre><code>val conf = new NeuralNetConfiguration.Builder()\n// Hyperparameters code here\n.list\n// Layers code here\n.setInputType(InputType.convolutionalFlat(28, 28, 1)) // Setting our input type here (784 linear array input converted to 28x28x1 input)\n.build\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1511006694424_-2042624967","id":"20171020-070710_1843650237","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:10+0000","dateFinished":"2017-11-20T15:07:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9193"},{"text":"%md\n\n### Imports","user":"anonymous","dateUpdated":"2017-11-20T15:07:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Imports</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1511188634263_-474174516","id":"20171120-143714_472543342","dateCreated":"2017-11-20T14:37:14+0000","dateStarted":"2017-11-20T15:07:10+0000","dateFinished":"2017-11-20T15:07:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9194"},{"text":"import java.{lang, util}\r\n\r\nimport org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\r\nimport org.deeplearning4j.nn.api.{Model, OptimizationAlgorithm}\r\nimport org.deeplearning4j.nn.conf.inputs.InputType\r\nimport org.deeplearning4j.nn.conf.layers.{ConvolutionLayer, DenseLayer, OutputLayer, SubsamplingLayer}\r\nimport org.deeplearning4j.nn.conf.{LearningRatePolicy, NeuralNetConfiguration, Updater}\r\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork\r\nimport org.deeplearning4j.nn.weights.WeightInit\r\nimport org.deeplearning4j.optimize.api.IterationListener\r\nimport org.nd4j.linalg.activations.Activation\r\nimport org.nd4j.linalg.lossfunctions.LossFunctions","user":"anonymous","dateUpdated":"2017-11-20T15:07:10+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.{lang, util}\nimport org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\nimport org.deeplearning4j.nn.api.{Model, OptimizationAlgorithm}\nimport org.deeplearning4j.nn.conf.inputs.InputType\nimport org.deeplearning4j.nn.conf.layers.{ConvolutionLayer, DenseLayer, OutputLayer, SubsamplingLayer}\nimport org.deeplearning4j.nn.conf.{LearningRatePolicy, NeuralNetConfiguration, Updater}\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.optimize.api.IterationListener\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.lossfunctions.LossFunctions\n"}]},"apps":[],"jobName":"paragraph_1511006694425_1809240874","id":"20171020-071303_1517144370","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:10+0000","dateFinished":"2017-11-20T15:07:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9195"},{"text":"%md\n\n### Setting up the network inputs\nWe'll use the __MNIST__ dataset for this tutorial.","user":"anonymous","dateUpdated":"2017-11-20T15:07:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Setting up the network inputs</h3>\n<p>We&rsquo;ll use the <strong>MNIST</strong> dataset for this tutorial.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1511006694425_522093421","id":"20171116-181214_1098994224","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:31+0000","dateFinished":"2017-11-20T15:07:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9196"},{"text":"val seed = 123\r\nval epochs = 1\r\nval batchSize = 64\r\nval learningRate = 0.1\r\nval learningRateDecay = 0.1\r\n\r\nval mnistTrain = new MnistDataSetIterator(batchSize, true, seed)\r\nval mnistTest = new MnistDataSetIterator(batchSize, false, seed)","user":"anonymous","dateUpdated":"2017-11-20T15:07:10+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"seed: Int = 123\nepochs: Int = 1\nbatchSize: Int = 64\nlearningRate: Double = 0.1\nlearningRateDecay: Double = 0.1\nmnistTrain: org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator = org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator@7b53a0e9\nmnistTest: org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator = org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator@746ab96\n"}]},"apps":[],"jobName":"paragraph_1511006694425_-1882966720","id":"20171116-181442_125385967","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:31+0000","dateFinished":"2017-11-20T15:07:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9197"},{"text":"%md\n\n### Creating a CNN network","user":"anonymous","dateUpdated":"2017-11-20T15:07:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Creating a CNN network</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1511006694426_375114696","id":"20171020-072208_966782035","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:33+0000","dateFinished":"2017-11-20T15:07:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9198"},{"text":"val lrSchedule: util.Map[Integer, lang.Double] = new util.HashMap[Integer, lang.Double]\r\nlrSchedule.put(0, learningRate)\r\nlrSchedule.put(1000, learningRate * learningRateDecay)\r\nlrSchedule.put(4000, learningRate * Math.pow(learningRateDecay, 2))\r\n\r\nval conf = new NeuralNetConfiguration.Builder()\r\n    .seed(seed)\r\n    .iterations(1)\r\n    .regularization(true).l2(0.005)\r\n    .activation(Activation.RELU)\r\n    .learningRateDecayPolicy(LearningRatePolicy.Schedule)\r\n    .learningRateSchedule(lrSchedule)\r\n    .weightInit(WeightInit.XAVIER)\r\n    .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\r\n    .updater(Updater.ADAM)\r\n    .list\r\n    .layer(0, new ConvolutionLayer.Builder(Array[Int](5, 5), Array[Int](1, 1), Array[Int](0, 0))\r\n      .name(\"cnn1\").nOut(50).biasInit(0).build)\r\n    .layer(1, new SubsamplingLayer.Builder(Array[Int](2, 2), Array[Int](2, 2)).name(\"maxpool1\").build)\r\n    .layer(2, new ConvolutionLayer.Builder(Array(5, 5), Array[Int](1, 1), Array[Int](0, 0))\r\n      .name(\"cnn2\").nOut(100).biasInit(0).build)\r\n    .layer(3, new SubsamplingLayer.Builder(Array[Int](2, 2), Array[Int](2, 2)).name(\"maxpool2\").build)\r\n    .layer(4, new DenseLayer.Builder().nOut(500).build)\r\n    .layer(5, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\r\n      .nOut(10).activation(Activation.SOFTMAX).build)\r\n    .backprop(true).pretrain(false)\r\n    .setInputType(InputType.convolutionalFlat(28, 28, 1))\r\n    .build\r\n\r\nval model = new MultiLayerNetwork(conf)\r\nmodel.init()\r\nmodel.setListeners(new IterationListener {\r\n  override def invoke(): Unit = ???   \r\n  override def iterationDone(model: Model, iteration: Int): Unit = {\r\n    if(iteration % 100 == 0) {\r\n      println(\"Score at iteration \" + iteration + \" is \" + model.score())\r\n    }\r\n  }   \r\n  override def invoked(): Nothing = ???\r\n})\r\n    \r\n(1 to epochs).foreach(epochStep => {\r\n  println(\"Epoch: \" + epochStep)\r\n  model.fit(mnistTrain)\r\n  // print the basic statistics about the trained classifier\r\n  println(\"Training Stats for epoch: \" + epochStep + \" -> \" + model.evaluate(mnistTest).stats(true))\r\n  mnistTest.reset()\r\n})","user":"anonymous","dateUpdated":"2017-11-20T15:07:10+0000","config":{"tableHide":false,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lrSchedule: java.util.Map[Integer,Double] = {}\nres0: Double = null\nres1: Double = null\nres2: Double = null\nconf: org.deeplearning4j.nn.conf.MultiLayerConfiguration =\n{\n  \"backprop\" : true,\n  \"backpropType\" : \"Standard\",\n  \"cacheMode\" : \"NONE\",\n  \"confs\" : [ {\n    \"cacheMode\" : \"NONE\",\n    \"iterationCount\" : 0,\n    \"l1ByParam\" : { },\n    \"l2ByParam\" : { },\n    \"layer\" : {\n      \"convolution\" : {\n        \"activationFn\" : {\n          \"ReLU\" : { }\n        },\n        \"adamMeanDecay\" : 0.9,\n        \"adamVarDecay\" : 0.999,\n        \"biasInit\" : 0.0,\n        \"biasLearningRate\" : 0.1,\n        \"convolutionMode\" : \"Truncate\",\n        \"cudnnAlgoMode\" : \"PREFER_FASTEST\",\n        \"cudnnBwdDataAlgo\" : null,\n        \"cudnnBwdFilterAlgo\" : null,\n        \"cudnnFwdAlgo\" : null,\n        \"dist\" : null,\n        \"dropOut\" : 0.0,\n        \"epsilon\" : 1.0E-8,\n        \"gradientNormalization\" : \"None\",\n        \"gradient...model: org.deeplearning4j.nn.multilayer.MultiLayerNetwork = org.deeplearning4j.nn.multilayer.MultiLayerNetwork@4331c88a\nEpoch: 1\nScore at iteration 0 is 2.3379802977228348\nScore at iteration 100 is 0.2669561267795874\nScore at iteration 200 is 0.21754097031737135\nScore at iteration 300 is 0.21722672677511565\nScore at iteration 400 is 0.11637009504284164\nScore at iteration 500 is 0.13475708434868477\nScore at iteration 600 is 0.07702370940008041\nScore at iteration 700 is 0.06152160806975777\nScore at iteration 800 is 0.10351134828877057\nScore at iteration 900 is 0.13980447216689168\nTraining Stats for epoch: 1 -> \nExamples labeled as 0 classified by model as 0: 977 times\nExamples labeled as 0 classified by model as 1: 1 times\nExamples labeled as 0 classified by model as 7: 1 times\nExamples labeled as 0 classified by model as 8: 1 times\nExamples labeled as 1 classified by model as 1: 1133 times\nExamples labeled as 1 classified by model as 2: 1 times\nExamples labeled as 1 classified by model as 7: 1 times\nExamples labeled as 2 classified by model as 0: 3 times\nExamples labeled as 2 classified by model as 1: 5 times\nExamples labeled as 2 classified by model as 2: 1018 times\nExamples labeled as 2 classified by model as 7: 5 times\nExamples labeled as 2 classified by model as 8: 1 times\nExamples labeled as 3 classified by model as 0: 1 times\nExamples labeled as 3 classified by model as 1: 1 times\nExamples labeled as 3 classified by model as 2: 2 times\nExamples labeled as 3 classified by model as 3: 1004 times\nExamples labeled as 3 classified by model as 8: 2 times\nExamples labeled as 4 classified by model as 4: 982 times\nExamples labeled as 5 classified by model as 0: 3 times\nExamples labeled as 5 classified by model as 3: 21 times\nExamples labeled as 5 classified by model as 5: 852 times\nExamples labeled as 5 classified by model as 6: 8 times\nExamples labeled as 5 classified by model as 7: 1 times\nExamples labeled as 5 classified by model as 8: 3 times\nExamples labeled as 5 classified by model as 9: 4 times\nExamples labeled as 6 classified by model as 0: 6 times\nExamples labeled as 6 classified by model as 1: 4 times\nExamples labeled as 6 classified by model as 4: 2 times\nExamples labeled as 6 classified by model as 5: 1 times\nExamples labeled as 6 classified by model as 6: 944 times\nExamples labeled as 6 classified by model as 8: 1 times\nExamples labeled as 7 classified by model as 1: 4 times\nExamples labeled as 7 classified by model as 3: 1 times\nExamples labeled as 7 classified by model as 4: 1 times\nExamples labeled as 7 classified by model as 7: 1020 times\nExamples labeled as 7 classified by model as 8: 1 times\nExamples labeled as 7 classified by model as 9: 1 times\nExamples labeled as 8 classified by model as 0: 13 times\nExamples labeled as 8 classified by model as 1: 2 times\nExamples labeled as 8 classified by model as 2: 2 times\nExamples labeled as 8 classified by model as 3: 1 times\nExamples labeled as 8 classified by model as 4: 2 times\nExamples labeled as 8 classified by model as 7: 2 times\nExamples labeled as 8 classified by model as 8: 945 times\nExamples labeled as 8 classified by model as 9: 7 times\nExamples labeled as 9 classified by model as 0: 4 times\nExamples labeled as 9 classified by model as 1: 2 times\nExamples labeled as 9 classified by model as 3: 1 times\nExamples labeled as 9 classified by model as 4: 25 times\nExamples labeled as 9 classified by model as 5: 2 times\nExamples labeled as 9 classified by model as 7: 7 times\nExamples labeled as 9 classified by model as 8: 2 times\nExamples labeled as 9 classified by model as 9: 966 times\n\n\n==========================Scores========================================\n # of classes:    10\n Accuracy:        0.9841\n Precision:       0.9844\n Recall:          0.9836\n F1 Score:        0.9839\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 10 classes)\n========================================================================\n"}]},"apps":[],"jobName":"paragraph_1511006694426_-908562333","id":"20171020-071349_473511535","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:07:33+0000","dateFinished":"2017-11-20T15:18:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9199"},{"text":"%md\n\n### Summary\n\nCNNs give better accuracy than normal fully-connected feedforward networks. As you can see in the above outputs, we got nearly 99% accuracy with just a simple CNN. There are manly favous CNN available online which you can study on your own, such as Alex Net, Le Net, google inception net etc.","user":"anonymous","dateUpdated":"2017-11-20T15:20:58+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Summary</h3>\n<p>CNNs give better accuracy than normal fully-connected feedforward networks. As you can see in the above outputs, we got nearly 99% accuracy with just a simple CNN. There are manly favous CNN available online which you can study on your own, such as Alex Net, Le Net, google inception net etc.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1511006694427_1208664961","id":"20171117-073125_214586916","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:20:58+0000","dateFinished":"2017-11-20T15:20:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9200"},{"text":"%md\n\n### What's next?\n\n- Check out all of our tutorials available [on Github](https://github.com/deeplearning4j/deeplearning4j/tree/master/dl4j-examples/tutorials). Notebooks are numbered for easy following.","user":"anonymous","dateUpdated":"2017-11-20T15:07:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>What&rsquo;s next?</h3>\n<ul>\n  <li>Check out all of our tutorials available <a href=\"https://github.com/deeplearning4j/deeplearning4j/tree/master/dl4j-examples/tutorials\">on Github</a>. Notebooks are numbered for easy following.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1511006694437_1371916728","id":"20171020-072151_195526063","dateCreated":"2017-11-18T12:04:54+0000","dateStarted":"2017-11-20T15:18:12+0000","dateFinished":"2017-11-20T15:18:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9202"},{"text":"%md\n","user":"anonymous","dateUpdated":"2017-11-20T14:53:30+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1511006694438_2126393092","id":"20171020-072158_2072802023","dateCreated":"2017-11-18T12:04:54+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:9203"}],"name":"Image classification with CNN","id":"2CZ3T5FJR","angularObjects":{"2CZQ7ZY6S:shared_process":[],"2D1CXP1PP:shared_process":[],"2CZ2UUD41:shared_process":[],"2D1AKPRZA:shared_process":[],"2CX1MZBK8:shared_process":[],"2CXVEN2YD:shared_process":[],"2CX4DY6NZ:shared_process":[],"2CXVDPAZN:shared_process":[],"2CXK9GBTB:shared_process":[],"2CXAT5DWH:shared_process":[],"2CXRBFGBY:shared_process":[],"2CZDYJPG9:shared_process":[],"2CY9RSS9K:shared_process":[],"2CZSZQC4M:shared_process":[],"2CYBYW659:shared_process":[],"2CZCD55JD:shared_process":[],"2CYAJA9NF:shared_process":[],"2D1FESVJD:shared_process":[],"2CYGUF5SA:shared_process":[],"2CZ4X76GG:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}